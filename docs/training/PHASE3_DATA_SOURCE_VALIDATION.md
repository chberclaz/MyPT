# Phase 3 Datasource Validation (v1)

> **Objective:** Validate every datasource used in Phase 3 against critical curriculum roles.  
> **Rule:** Each source must satisfy **at least 2 critical roles** for this phase.  
> **Pipeline reference:** `scripts/sft/build_phase3_dataset.py`, `docs/sft/SFT_PIPELINE_GUIDE.md`.

---

## 1) Critical Roles For Phase 3

These are the critical roles for this stage (obedience-first instruction tuning):

1. **Schema stability**: consistent `system/user/assistant` turn structure.
2. **Checkable obedience**: crisp tasks with objectively checkable outputs.
3. **Constraint precision**: strict output control (`return only`, no extras, schema exactness).
4. **Conflict hierarchy**: system-over-user behavior under conflicting instructions.
5. **Prompt-injection resistance**: refuse "ignore system" style attacks.
6. **Abstention behavior**: "not enough information" when context is insufficient.
7. **Grounded answering**: answer from provided context only.
8. **Citation behavior**: cite source when grounded context is used.
9. **Maintenance - operator exactness**: preserve COPY/WRAP/EXTRACT precision.
10. **Maintenance - anti-echo**: avoid parroting forbidden/gibberish tokens.
11. **Conversation robustness**: multilingual/open style coverage to avoid brittle behavior.
12. **Short multi-turn memory**: 2-4 turn local context continuity.

---

## 2) Phase 3 Sources Under Validation

Current Phase 3 build uses these inputs:

- `data/sft_phase3_intermediate/phase3_precision.jsonl` (generated by `generate_phase3_precision_sft.py`)
- `data/sft_phase3_intermediate/rag_chat.jsonl` (generated by `generate_rag_chat_sft.py`)
- `data/sft_phase2_intermediate/operators/operator_train.jsonl` (operators replay)
- `data/sft_phase2_6_intermediate/phase2_6_mixed_train.jsonl` (anti-echo replay)
- `data/sft_hf/oasst2.jsonl` (HF open chat)
- `data/sft_hf/alpaca_de.jsonl` (HF open chat / instruction)
- `data/sft_phase3_intermediate/gold_augmented.jsonl` (augmented project gold)

---

## 3) Source Validation Matrix

## Pass Criteria

- A source **passes** if it contributes at least **2 critical roles** above.
- A source can be included for replay/maintenance if it is narrow, but still must contribute 2 roles.

| Source | Primary Function | Critical Roles Covered | Role Count | Verdict |
|---|---|---|---:|---|
| `phase3_precision.jsonl` | High-precision checkable instruction tasks | Checkable obedience (2), constraint precision (3), conflict hierarchy (4), injection resistance (5), abstention (6), schema stability (1) | 6 | PASS |
| `rag_chat.jsonl` | Grounded context chat + cite/think shape | Grounded answering (7), citation behavior (8), abstention via insufficient-context templates (6), short multi-turn memory (12), schema stability (1) | 5 | PASS |
| `operator_train.jsonl` replay | Preserve operator circuits | Maintenance operator exactness (9), constraint precision (3), checkable obedience (2) | 3 | PASS |
| `phase2_6_mixed_train.jsonl` replay | Preserve anti-echo/constraint refusal | Maintenance anti-echo (10), prompt-injection-adjacent refusal to repeat forbidden strings (5), constraint precision (3) | 3 | PASS |
| `oasst2.jsonl` | Broad multilingual conversational robustness | Conversation robustness (11), short multi-turn memory (12), schema stability (1) | 3 | PASS |
| `alpaca_de.jsonl` | German instruction variety | Checkable obedience (2), conversation robustness (11), schema stability (1) | 3 | PASS |
| `gold_augmented.jsonl` | Preserve project style and canonical behavior | Schema stability (1), conversation robustness (11), short multi-turn memory (12, where present) | 3 | PASS |

---

## 4) Strict Findings (Per Source)

### A) `phase3_precision.jsonl` (new generator)
- Strongest source for obedience-first Phase 3.
- Directly targets the most important missing alignment signals (conflicts, strict output, abstention).
- Risk: can become overly synthetic if over-weighted.
- Mitigation: keep grounded + open-chat components active (already enforced by policy mixer).

### B) `rag_chat.jsonl`
- Correctly introduces runtime shape: `user_context`, optional `think`, `cite`.
- Provides grounded answer behavior and "insufficient context" behavior.
- Risk: weak citation quality if source identifiers are noisy.
- Mitigation: retain context->cite linkage audit and context-citation eval bucket.

### C) `operator_train.jsonl`
- High-value maintenance source to prevent operator collapse.
- Risk: overfitting to old templates if overweighted.
- Mitigation: keep ratio in maintenance band (5-10%) and rely on NOVEL eval templates.

### D) `phase2_6_mixed_train.jsonl`
- Preserves anti-echo behavior and refusal constraints.
- Risk: if overweighted, can hurt general regression/operator behavior (observed previously).
- Mitigation: keep low maintenance ratio (2-5%), monitor regression bucket.

### E) `oasst2.jsonl`
- Broad robustness source; useful for natural user phrasing and turn variety.
- Risk: too much open-ended data can dilute strict obedience.
- Mitigation: open-chat cap in Phase 3 mixer.

### F) `alpaca_de.jsonl`
- Strong German instruction diversity with generally checkable format.
- Risk: can include verbose answer styles that conflict with strict-output goals.
- Mitigation: keep as capped open-chat contributor, not dominant source.

### G) `gold_augmented.jsonl`
- Preserves project-specific style and conversational continuity.
- Risk: paraphrase drift can introduce softer, less strict response norms.
- Mitigation: position it under open-chat cap and audit strict-format rate after mixing.

---

## 5) Coverage Against Phase 3 Requirements

| Requirement | Satisfied by Sources |
|---|---|
| Strict consistent chat schema | All sources after `prepare_chat_sft.py` serialization + schema validation |
| Checkable tasks dominate early Phase 3 | `phase3_precision` + `operator_train` + part of `alpaca_de` |
| Negative constraints / conflicts | `phase3_precision` + anti-echo replay |
| Abstention / don't know | `phase3_precision` + `rag_chat` insufficient-context pattern |
| Tight output formatting | `phase3_precision` + operator replay |
| Short-first multi-turn | `rag_chat` + `oasst2` + `gold_augmented` (plus mixer turn cap) |
| Maintenance replay | `operator_train` + `phase2_6_mixed_train` |
| Inference-shape training | `rag_chat` (+ `prepare_chat_sft --enable_rag_tags`) |

Result: **All required capability clusters are covered by at least one dedicated source and one backup source.**

---

## 6) Quantitative Acceptance Checks (Before Training)

Run these checks on final mixed file (`phase3_mixed.jsonl`):

1. `python scripts/sft/audit_phase3_dataset.py --input data/sft_phase3_intermediate/phase3_mixed.jsonl --output data/sft_phase3_intermediate/phase3_mixed.audit.json`
2. Confirm:
   - `checkable_rate` is dominant versus open-ended.
   - `operators_rate` and `anti_echo_rate` remain in maintenance bands.
   - `grounded_qa_rate` is >= target band.
   - `context_to_cite_rate` is high (goal: close to 100% on grounded turns).
3. Tokenization gate:
   - `python scripts/sft/prepare_chat_sft.py ... --schema_validation_mode error --enable_rag_tags`
4. Model gate (after training):
   - `sft_eval_suite.py` + `run_regression_gate.py --phase 3` with new buckets.

---

## 7) Final Verdict

- **All currently selected Phase 3 datasources pass** the rule "**>=2 critical roles per source**".
- Source portfolio is now balanced for Phase 3 objective: obedience + hierarchy + abstention + precision + maintenance.
- Main operational risk remains over-weighting open-ended chat or anti-echo replay; current policy mixer and hard gate are designed to catch this early.

---

## 8) Ten Must-Have Checks (Status)

| # | Must-have | Status | Enforcement |
|---|---|---|---|
| 1 | `phase3_precision` as spine without synthetic template overfit | Implemented | `generate_phase3_precision_sft.py` now uses expanded lexical perturbations + diversity proxy (`validate_dataset_quality`) |
| 2 | Explicit hierarchy conflicts in data | Implemented | `build_conflict_examples()` with system-over-user violations and exact short outputs |
| 3 | Adversarial negative retrieval (plausible but irrelevant) + conflict sources | Implemented | `generate_rag_chat_sft.py`: `generate_insufficient_context()` now distractor-topic; added `generate_conflicting_context()` |
| 4 | Citation mechanically checkable with closed-set refs | Implemented | RAG contexts now include `[CID:<chunk_id>]`; assistant `cite` references chunk IDs; eval `context_citation` checks allowed ref set |
| 5 | Style firewall against quote/backtick drift | Implemented | Precision tasks enforce no-markdown/no-quotes/no-extra-text families; strict-format eval bucket present |
| 6 | Operators + anti-echo as maintenance, not capability drivers | Implemented | `build_phase3_dataset.py` defaults: operators 8%, anti-echo 2%, grounded 16%, open-chat cap |
| 7 | Short multi-turn dependency examples | Implemented | `generate_phase3_precision_sft.py` adds follow-up dependency episodes (`build_followup_dependency_examples`) |
| 8 | Tool-free discipline before tool phases | Implemented | `build_toolfree_discipline_examples()` in precision generator |
| 9 | Phase-3 eval micro-buckets (hierarchy, grounded distractor, strict output) | Implemented | `sft_eval_suite.py` has `instruction_hierarchy`, `abstention_context`, `strict_format`, `prompt_injection`, `context_citation` |
| 10 | Replay anti-echo only “good shape” outputs | Implemented | `build_phase3_dataset.py` anti-echo filter upgraded to `_is_clean_anti_echo()` (drops leakage of forbidden quoted token) |

### Operational Note

These checks are now split between:
- **data construction-time** controls (generators + policy mixer),
- **pre-tokenization audits** (`audit_phase3_dataset.py`),
- **post-training gates** (`sft_eval_suite.py`, `run_regression_gate.py`).

